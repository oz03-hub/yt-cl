- We get more visible distinct clusters when less than 100 and greater, when mixed things get more ambiguous
- There are some clear outliers in the data, we can try to remove them, see how much they deviate from the general clump of points
- You can see clustering in PCA more clearly if you set limits on the axes
- We can see anomalies in transcript by looking at the normalized transcripts and calculating the lexical diversity
- Very low diversity, 0.05, show repetitive content, which might be from music videos, confusing the model
- bow might not be the best representation for this data, we can try to use tf-idf
- Clusters on graph look much more promising for embedding based clusterings
- inertia performs better when two corpuses are clustered individually, clustering all together results in a higher inertia. Inertia almost doubles, this might also be because we consider twice as many data points
- silhouette score is low for all corporas, we need a way to separate the clusters more, it is average performance right now, slightly better for less than 100 words corpus
- We could try to remove more common words and start incorporating document length normalization
- A higher value of CH indicates a better clustering, because it means that the data points are more spread out between clusters than they are within clusters.
- I think we need to take another look at preprocessing to prioritize more context bearing tokens
- We can also try applying hierarchical clustering, LSA
- silhouette, how well clusters are separated, better defined clusters
- davies, similarity between clusters
- calinski, well separated, dense clusters
- create document embeddings by weighting each word embedding with its tf-idf value and normalize by document length
- how can we handle out of vocabulary words? we can train fasttext on the corpus
- ensemble, find different embeddings through different techniques, average to make a decision

- Very clear clusters are about mechanic diy / car review, religion, rap a lot of profanities, cooking/baking, gaming
- A good cluster amount seems in range 10, 20. Even getting closer to 20 topics start to degrade
- Removing stopwords after training is just as effective as removing them before.
- Removing stopwords simply reduce the amount of probability mass and smoothing of the model caused by frequent non-topic terms
- Corpus specific stoplists provide little utility, it is sufficient to remove obvious stopwords
- post-hoc stopword removal can significantly improve coherence

- post-hoc removal helped to identify topics easier, I notice with lower number of clusters, 10-15 some topics are still visible, car, religion, rap, gaming. Increasing cluster size creates more sub-topics, seems like gaming gets split more, and we see more emerging topics like chemistry, math, biology in 30 clusters, but also more non-sense generic classes

- I think post-hoc custom stop removal is very beneficial
- Some clusters do have significantly more lengthy documents
